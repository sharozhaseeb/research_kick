{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nYou are a Professional Research Advisor who work for Research Boost. You help users with research ideas by asking questions to build context, then search PubMed and then respond with a structured response. \\nYou ask insightful yet conversational questions to probe the user’s ideas, knowledge, and observations. Your role is to help connect abstract thoughts to concrete research ideas while ensuring the user feels supported and engaged in the process. \\n\\n<First Step>\\nYour task is to lightly interview the user;\\n\\nStart with an easy, open question that invites the user to share a thought or observation. Build on their response with follow-up questions. \\nAsk one question per turn. \\nDon't ask more than 5 questions in total.\\nAvoid overly technical or complex questions initially; keep them conversational and engaging.\\nLet the conversation flow naturally to build trust and comfort.\\n\\n<Second Step>\\nAfter you have enough context and know the relevant keywords, Search PubMed for research articles using them. \\n\\n<Third Step>\\nAfter you get the PubMed response, respond to the user with 5 new research ideas after critically analyzing the PubMed response.\\nAlso add the names of the articles as sources at the end of the response.\\n\\n<Forth Step>\\nGenerate a Concept Map(Mermaid Diagram) that visualizes various research directions for the current context. This map will group ideas into several major themes and breaks down each theme into subtopics.\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "You are a Professional Research Advisor who work for Research Boost. You help users with research ideas by asking questions to build context, then search PubMed and then respond with a structured response. \n",
    "You ask insightful yet conversational questions to probe the user’s ideas, knowledge, and observations. Your role is to help connect abstract thoughts to concrete research ideas while ensuring the user feels supported and engaged in the process. \n",
    "\n",
    "<First Step>\n",
    "Your task is to lightly interview the user;\n",
    "\n",
    "Start with an easy, open question that invites the user to share a thought or observation. Build on their response with follow-up questions. \n",
    "Ask one question per turn. \n",
    "Don't ask more than 5 questions in total.\n",
    "Avoid overly technical or complex questions initially; keep them conversational and engaging.\n",
    "Let the conversation flow naturally to build trust and comfort.\n",
    "\n",
    "<Second Step>\n",
    "After you have enough context and know the relevant keywords, Search PubMed for research articles using them. \n",
    "\n",
    "<Third Step>\n",
    "After you get the PubMed response, respond to the user with 5 new research ideas after critically analyzing the PubMed response.\n",
    "Also add the names of the articles as sources at the end of the response.\n",
    "\n",
    "<Forth Step>\n",
    "Generate a Concept Map(Mermaid Diagram) that visualizes various research directions for the current context. This map will group ideas into several major themes and breaks down each theme into subtopics.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pymed import PubMed\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found. Check your .env file.\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def pubmed_search(query, max_results=5):\n",
    "    pubmed = PubMed(tool=\"MyTool\", email=\"sharozhaseeb1@gmail.com\")\n",
    "    results = pubmed.query(query, max_results=max_results)\n",
    "\n",
    "    result_list = []\n",
    "    for article in results:\n",
    "        child_dict = {}\n",
    "        child_dict['title'] = article.title\n",
    "        child_dict['authors'] = [((author['lastname'] or '') + ', ' + (author['firstname'] or '')).strip(', ') for author in article.authors]\n",
    "        child_dict['abstract'] = article.abstract\n",
    "        child_dict['publication_date'] = article.publication_date\n",
    "        result_list.append(child_dict)\n",
    "    \n",
    "    return result_list\n",
    "\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"pubmed_search\",\n",
    "        \"description\": \"Searches PubMed for research articles based on a given query.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The keyword to search for.\"\n",
    "                },\n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The maximum number of results to retrieve.\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a Professional Research Advisor who work for Research Boost. You help users with research ideas by asking questions to build context, then search PubMed and then respond with a structured response. \\nYou ask insightful yet conversational questions to probe the user’s ideas, knowledge, and observations. Your role is to help connect abstract thoughts to concrete research ideas while ensuring the user feels supported and engaged in the process. \\n\\n<First Step>\\nYour task is to lightly interview the user;\\n\\nStart with an easy, open question that invites the user to share a thought or observation. Build on their response with follow-up questions. \\nAsk one question per turn. \\nDon't ask more than 5 questions in total.\\nAvoid overly technical or complex questions initially; keep them conversational and engaging.\\nLet the conversation flow naturally to build trust and comfort.\\n\\n<Second Step>\\nAfter you have enough context and know the relevant keywords, Search PubMed for research articles using them. \\n\\n<Third Step>\\nAfter you get the PubMed response, respond to the user with 5 new research ideas after critically analyzing the PubMed response.\\nAlso add the names of the articles as sources at the end of the response.\\n\\n<Forth Step>\\nGenerate a Concept Map(Mermaid Diagram) that visualizes various research directions for the current context. This map will group ideas into several major themes and breaks down each theme into subtopics.\"},\n",
    "            {\"role\": \"user\", \"content\": \"I work in machine learning specifically transformers, can you get me some research ideas?\"}]\n",
    "            # {\"role\": \"user\", \"content\": \"Hi, who are you ?\"}]\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    # tool_choice=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_euOxD1SrpSINfZ6O8fzSWs5J', function=Function(arguments='{\"query\":\"transformers machine learning\",\"max_results\":5}', name='pubmed_search'), type='function')], annotations=[]))\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tool_calls'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].finish_reason\n",
    "\n",
    "#output for tool call will be 'tool_calls'\n",
    "#output for chat will be 'stop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_euOxD1SrpSINfZ6O8fzSWs5J', 'function': {'arguments': '{\"query\":\"transformers machine learning\",\"max_results\":5}', 'name': 'pubmed_search'}, 'type': 'function'}\n"
     ]
    }
   ],
   "source": [
    "tool_calls = completion.choices[0].message.tool_calls\n",
    "\n",
    "for tool_call in tool_calls:\n",
    "    print(tool_call.to_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = completion.choices[0].message.tool_calls[0]\n",
    "args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "result = pubmed_search(args[\"query\"], args[\"max_results\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Accelerating the inference of string generation-based chemical reaction models for industrial applications.', 'authors': ['Andronov, Mikhail', 'Andronova, Natalia', 'Wand, Michael', 'Schmidhuber, Jürgen', 'Clevert, Djork-Arné'], 'abstract': \"Transformer-based, template-free SMILES-to-SMILES translation models for reaction prediction and single-step retrosynthesis are of interest to computer-aided synthesis planning systems, as they offer state-of-the-art accuracy. However, their slow inference speed limits their practical utility in such applications. To address this challenge, we propose speculative decoding with a simple chemically specific drafting strategy and apply it to the Molecular Transformer, an encoder-decoder transformer for conditional SMILES generation. Our approach achieves over 3X faster inference in reaction product prediction and single-step retrosynthesis with no loss in accuracy, increasing the potential of the transformer as the backbone of synthesis planning systems. To accelerate the simultaneous generation of multiple precursor SMILES for a given query SMILES in single-step retrosynthesis, we introduce Speculative Beam Search, a novel algorithm tackling the challenge of beam search acceleration with speculative decoding. Our methods aim to improve transformer-based models' scalability and industrial applicability in synthesis planning.\", 'publication_date': datetime.date(2025, 3, 11)}, {'title': 'Principal component analysis and fine-tuned vision transformation integrating model explainability for breast cancer prediction.', 'authors': ['Luong, Huong Hoang', 'Hong, Phuc Phan', 'Minh, Dat Vo', 'Quang, Thinh Nguyen Le', 'The, Anh Dinh', 'Thai-Nghe, Nguyen', 'Nguyen, Hai Thanh'], 'abstract': 'Breast cancer, which is the most commonly diagnosed cancers among women, is a notable health issues globally. Breast cancer is a result of abnormal cells in the breast tissue growing out of control. Histopathology, which refers to the detection and learning of tissue diseases, has appeared as a solution for breast cancer treatment as it plays a vital role in its diagnosis and classification. Thus, considerable research on histopathology in medical and computer science has been conducted to develop an effective method for breast cancer treatment. In this study, a vision Transformer (ViT) was employed to classify tumors into two classes, benign and malignant, in the Breast Cancer Histopathological Database (BreakHis). To enhance the model performance, we introduced the novel multi-head locality large kernel self-attention during fine-tuning, achieving an accuracy of 95.94% at 100× magnification, thereby improving the accuracy by 3.34% compared to a standard ViT (which uses multi-head self-attention). In addition, the application of principal component analysis for dimensionality reduction led to an accuracy improvement of 3.34%, highlighting its role in mitigating overfitting and reducing the computational complexity. In the final phase, SHapley Additive exPlanations, Local Interpretable Model-agnostic Explanations, and Gradient-weighted Class Activation Mapping were used for the interpretability and explainability of machine-learning models, aiding in understanding the feature importance and local explanations, and visualizing the model attention. In another experiment, ensemble learning with VGGIN further boosted the performance to 97.13% accuracy. Our approach exhibited a 0.98% to 17.13% improvement in accuracy compared with state-of-the-art methods, establishing a new benchmark for breast cancer histopathological image classification.', 'publication_date': datetime.date(2025, 3, 10)}, {'title': \"A novel integrative multimodal classifier to enhance the diagnosis of Parkinson's disease.\", 'authors': ['Zhou, Xiaoyan', 'Parisi, Luca', 'Huang, Wentao', 'Zhang, Yihan', 'Huang, Xiaoqun', 'Youseffi, Mansour', 'Javid, Farideh', 'Ma, Renfei'], 'abstract': \"Parkinson's disease (PD) is a complex, progressive neurodegenerative disorder with high heterogeneity, making early diagnosis difficult. Early detection and intervention are crucial for slowing PD progression. Understanding PD's diverse pathways and mechanisms is key to advancing knowledge. Recent advances in noninvasive imaging and multi-omics technologies have provided valuable insights into PD's underlying causes and biological processes. However, integrating these diverse data sources remains challenging, especially when deriving meaningful low-level features that can serve as diagnostic indicators. This study developed and validated a novel integrative, multimodal predictive model for detecting PD based on features derived from multimodal data, including hematological information, proteomics, RNA sequencing, metabolomics, and dopamine transporter scan imaging, sourced from the Parkinson's Progression Markers Initiative. Several model architectures were investigated and evaluated, including support vector machine, eXtreme Gradient Boosting, fully connected neural networks with concatenation and joint modeling (FCNN_C and FCNN_JM), and a multimodal encoder-based model with multi-head cross-attention (MMT_CA). The MMT_CA model demonstrated superior predictive performance, achieving a balanced classification accuracy of 97.7%, thus highlighting its ability to capture and leverage cross-modality inter-dependencies to aid predictive analytics. Furthermore, feature importance analysis using SHapley Additive exPlanations not only identified crucial diagnostic biomarkers to inform the predictive models in this study but also holds potential for future research aimed at integrated functional analyses of PD from a multi-omics perspective, ultimately revealing targets required for precision medicine approaches to aid treatment of PD aimed at slowing down its progression.\", 'publication_date': datetime.date(2025, 3, 10)}, {'title': 'Non-invasive enhanced hypertension detection through ballistocardiograph signals with Mamba model.', 'authors': ['Alhudhaif, Adi', 'Polat, Kemal'], 'abstract': \"This study explores using ballistocardiography (BCG), a non-invasive cardiovascular monitoring technique, combined with advanced machine learning and deep learning models for hypertension detection. The motivation behind this research is to develop a non-invasive and efficient approach for long-term hypertension monitoring, facilitating home-based health assessments. A dataset of 128 BCG recordings has been used, capturing body micro-vibrations from cardiac activity. Various classification models, including Mamba Classifier, Transformer, Stacking, Voting, and XGBoost, were applied to differentiate hypertensive individuals from normotensive ones. In this study, integrating BCG signals with deep learning and machine learning models for hypertension detection is distinguished from previous literature by employing the Mamba deep learning architecture and Transformer-based models. Unlike conventional methods in literature, this study enables more effective analysis of time-series data with the Mamba architecture, capturing long-term signal dependencies and achieving higher accuracy rates. In particular, the combined use of Mamba architecture and the Transformer model's signal processing capabilities represents a novel approach not previously seen in the literature. While existing studies on BCG signals typically rely on traditional machine learning algorithms, this study aims to achieve higher success rates in hypertension detection by integrating signal processing and deep learning stages. The Mamba Classifier outperformed other models, achieving an accuracy of 95.14% and an AUC of 0.9922 in the 25% hold-out validation. Transformer and Stacking models also demonstrated strong performance, while the Voting and XGBoost models showed comparatively lower results. When combined with artificial intelligence techniques, the findings indicate the potential of BCG signals in providing non-invasive, long-term hypertension detection. The results suggest that the Mamba Classifier is the most effective model for this dataset. This research underscores the potential of BCG technology for continuous home-based health monitoring, providing a feasible alternative to traditional methods. Future research should aim to validate these findings with larger datasets and explore the clinical applications of BCG for cardiovascular disease monitoring.\", 'publication_date': datetime.date(2025, 3, 10)}, {'title': 'Predicting amyloid proteins using attention-based long short-term memory.', 'authors': ['Li, Zhuowen'], 'abstract': \"Alzheimer's disease (AD) is one of the genetically inherited neurodegenerative disorders that mostly occur when people get old. It can be recognized by severe memory impairment in the late stage, affecting cognitive function and general daily living. Reliable evidence confirms that the enhanced symptoms of AD are linked to the accumulation of amyloid proteins. The dense population of amyloid proteins forms insoluble fibrillar structures, causing significant pathological impacts in various tissues. Understanding amyloid protein's mechanisms and identifying them at an early stage plays an essential role in treating AD as well as prevalent amyloid-related diseases. Recently, although several machine learning methods proposed for amyloid protein identification have shown promising results, most of them have not yet fully exploited the sequence information of the amyloid proteins. In this study, we develop a computational model for \", 'publication_date': datetime.date(2025, 3, 10)}]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "\n",
    "def convert_pubmed_resp_to_str(articles):\n",
    "    master_str = \"\"\n",
    "    for article in articles:\n",
    "        formatted_string = f\"\"\"Title: {article['title']}\n",
    "        Authors: {', '.join(article['authors'])}\n",
    "        Abstract: {article['abstract']}\n",
    "        Publication Date: {article['publication_date'].strftime('%Y-%m-%d')}\n",
    "        {'-' * 80}\\n\"\"\"\n",
    "        master_str += formatted_string\n",
    "    return str(master_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_str = convert_pubmed_resp_to_str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(completion.choices[0].message)  # append model's function call message\n",
    "messages.append({                               # append result message\n",
    "    \"role\": \"tool\",\n",
    "    \"tool_call_id\": tool_call.id,\n",
    "    \"content\": results_str\n",
    "})\n",
    "\n",
    "completion_2 = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Here is a summary of recent research articles related to transformers in machine learning:\\n\\n1. **Accelerating the Inference of String Generation-Based Chemical Reaction Models for Industrial Applications**\\n   - **Authors**: Andronov, Mikhail; Andronova, Natalia; Wand, Michael; Schmidhuber, Jürgen; Clevert, Djork-Arné\\n   - **Abstract**: This study focuses on improving the inference speed of transformer-based SMILES-to-SMILES translation models used for reaction prediction and retrosynthesis. The authors introduce speculative decoding and Speculative Beam Search to achieve over 3 times faster inference without sacrificing accuracy. This advancement enhances the practical utility of transformers in synthesis planning systems.\\n   - **Publication Date**: March 11, 2025\\n\\n2. **Principal Component Analysis and Fine-Tuned Vision Transformation Integrating Model Explainability for Breast Cancer Prediction**\\n   - **Authors**: Luong, Huong Hoang; Hong, Phuc Phan; Minh, Dat Vo; Quang, Thinh Nguyen Le; The, Anh Dinh; Thai-Nghe, Nguyen; Nguyen, Hai Thanh\\n   - **Abstract**: The study employs Vision Transformers (ViT) to classify breast cancer tumors. Enhancements include the use of multi-head locality large kernel self-attention and principal component analysis for improved accuracy and reduced computational complexity. Interpretable machine learning techniques are used to understand feature importance, achieving a significant accuracy improvement.\\n   - **Publication Date**: March 10, 2025\\n\\n3. **A Novel Integrative Multimodal Classifier to Enhance the Diagnosis of Parkinson's Disease**\\n   - **Authors**: Zhou, Xiaoyan; Parisi, Luca; Huang, Wentao; Zhang, Yihan; Huang, Xiaoqun; Youseffi, Mansour; Javid, Farideh; Ma, Renfei\\n   - **Abstract**: This research explores a multimodal predictive model integrating diverse data (such as hematological information and imaging) to detect Parkinson's disease. A multimodal encoder-based model with multi-head cross-attention (MMT_CA) yielded high predictive accuracy. The study also highlights potential precision medicine applications.\\n   - **Publication Date**: March 10, 2025\\n\\n4. **Non-Invasive Enhanced Hypertension Detection Through Ballistocardiograph Signals with Mamba Model**\\n   - **Authors**: Alhudhaif, Adi; Polat, Kemal\\n   - **Abstract**: This research introduces a novel approach using ballistocardiography signals and transformer-based models for hypertension detection. The Mamba deep learning architecture is employed for effective long-term signal analysis. The study suggests this method for potential continuous home-based health monitoring.\\n   - **Publication Date**: March 10, 2025\\n\\n5. **Predicting Amyloid Proteins Using Attention-Based Long Short-Term Memory**\\n   - **Authors**: Li, Zhuowen\\n   - **Abstract**: This study develops a model for the early identification of amyloid proteins, critical for addressing Alzheimer's disease. While the full abstract was not available, the use of attention-based long short-term memory suggests innovative exploitation of sequence information for amyloid protein identification.\\n   - **Publication Date**: March 10, 2025\\n\\nThese articles highlight various applications and advancements of transformer models in diverse fields such as chemistry, healthcare, and neurodegenerative disease diagnostics. They offer a range of research ideas for applying transformer models in biological and medical data processing, as well as industrial applications.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))\n"
     ]
    }
   ],
   "source": [
    "print(completion_2.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "def install_mermaid_cli():\n",
    "    \"\"\"\n",
    "    Checks if mermaid-cli (mmdc) is installed. If not, installs it using npm.\n",
    "    \"\"\"\n",
    "    if shutil.which(\"mmdc\") is None:\n",
    "        print(\"Mermaid-cli (mmdc) not found. Installing...\")\n",
    "        try:\n",
    "            subprocess.run([\"npm\", \"install\", \"-g\", \"@mermaid-js/mermaid-cli\"], check=True)\n",
    "            print(\"Mermaid-cli installed successfully!\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error installing mermaid-cli: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"Mermaid-cli is already installed.\")\n",
    "    return True\n",
    "\n",
    "def mermaid_to_svg(input_mmd: str, output_svg: str):\n",
    "    \"\"\"\n",
    "    Converts a Mermaid diagram (.mmd) into an SVG file using the mermaid-cli (mmdc).\n",
    "    Installs mermaid-cli if not found.\n",
    "\n",
    "    :param input_mmd: Path to the input .mmd file.\n",
    "    :param output_svg: Path to save the output .svg file.\n",
    "    \"\"\"\n",
    "    if not install_mermaid_cli():\n",
    "        print(\"Mermaid-cli installation failed. Exiting.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Run the mmdc command to generate the SVG\n",
    "        subprocess.run([\"mmdc\", \"-i\", input_mmd, \"-o\", output_svg], check=True)\n",
    "        print(f\"Successfully converted {input_mmd} to {output_svg}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during conversion: {e}\")\n",
    "\n",
    "# Example usage\n",
    "mermaid_to_svg(\"diagram.mmd\", \"output.svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pubmed_search\n"
     ]
    }
   ],
   "source": [
    "# vas = {'id': 'call_euOxD1SrpSINfZ6O8fzSWs5J', 'function': {'arguments': '{\"query\":\"transformers machine learning\",\"max_results\":5}', 'name': 'pubmed_search'}, 'type': 'function'}\n",
    "\n",
    "# print(vas['function']['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'d': 2}]\n"
     ]
    }
   ],
   "source": [
    "vas = [{\"d\":2}]\n",
    "l = []\n",
    "vas.extend(l)\n",
    "print(vas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "for i in vas:\n",
    "    print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
